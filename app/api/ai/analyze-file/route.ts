import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { GoogleGenerativeAI } from '@google/generative-ai';
import OpenAI from 'openai';
import * as XLSX from 'xlsx';
// @ts-ignore
import pdfParse from 'pdf-parse';
import { Buffer } from 'buffer';

// Configuration
export const maxDuration = 60; // 60 secondes max
export const dynamic = 'force-dynamic';

// Timeout pour les appels API
const API_TIMEOUT_MS = 25000;

// Helper function to add timeout to promises
function withTimeout<T>(promise: Promise<T>, timeoutMs: number, errorMessage: string): Promise<T> {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) =>
      setTimeout(() => reject(new Error(errorMessage)), timeoutMs)
    )
  ]);
}

// Client Gemini 2.0 Flash (principal)
const getGeminiClient = () => {
  const apiKey = process.env.GOOGLE_AI_API_KEY || process.env.GEMINI_API_KEY;
  if (!apiKey) return null;
  return new GoogleGenerativeAI(apiKey);
};

// Initialiser DeepSeek (fallback)
const getDeepSeekClient = () => {
  const apiKey = process.env.DEEPSEEK_API_KEY;
  if (!apiKey) return null;
  return new OpenAI({
    apiKey,
    baseURL: 'https://api.deepseek.com/v1',
  });
};

// Initialiser Supabase avec service role
const getSupabaseClient = () => {
  return createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
  );
};

// Cat√©gories par secteur
const SECTOR_CATEGORIES: Record<string, string[]> = {
  'btp': [
    'Gros ≈ìuvre & Mat√©riaux',
    '√âlectricit√©',
    'Plomberie & Sanitaire',
    'Menuiserie & Bois',
    'Peinture & Finitions',
    'Carrelage & Rev√™tements',
    'Quincaillerie & Fixations',
    'Outillage & √âquipement',
    'S√©curit√© & Protection (EPI)',
    'Transport & Levage',
    'Installation de chantier',
    'Divers',
  ],
  'import': [
    '√âlectronique & High-Tech',
    'Textile & Habillement',
    'Mobilier & D√©coration',
    '√âquipement industriel',
    'Pi√®ces d√©tach√©es',
    'Mati√®res premi√®res',
    'Accessoires',
    'Divers',
  ],
  'commerce': [
    'Produits alimentaires',
    'Cosm√©tiques & Hygi√®ne',
    '√âlectrom√©nager',
    'Mobilier',
    'Textile',
    'Papeterie & Bureau',
    'Divers',
  ],
  'default': [
    '√âquipement',
    'Mat√©riaux',
    'Fournitures',
    'Services',
    'Divers',
  ],
};

export async function POST(request: NextRequest) {
  const startTime = Date.now();

  try {
    const { projectId, filePath, fileName } = await request.json();

    console.log('üìÇ === ANALYSE FICHIER D√âMARR√âE ===');
    console.log(`üìÅ Projet: ${projectId}`);
    console.log(`üìÑ Fichier: ${fileName}`);
    console.log(`üìç Chemin: ${filePath}`);

    if (!projectId || !filePath) {
      return NextResponse.json(
        { error: 'Project ID and file path are required' },
        { status: 400 }
      );
    }

    const supabase = getSupabaseClient();

    // 0. R√©cup√©rer les infos du projet (secteur)
    const { data: projectData, error: projectError } = await supabase
      .from('projects')
      .select(`
        *,
        sector:sectors(id, name, slug)
      `)
      .eq('id', projectId)
      .single();

    if (projectError) {
      console.error('‚ùå Project fetch error:', projectError);
    }

    const sectorSlug = projectData?.sector?.slug || 'default';
    const sectorName = projectData?.sector?.name || 'G√©n√©ral';
    console.log(`üè≠ Secteur d√©tect√©: ${sectorName} (${sectorSlug})`);

    // 1. T√©l√©charger le fichier depuis Supabase Storage
    console.log('üì• T√©l√©chargement du fichier...');
    const { data: fileData, error: downloadError } = await supabase.storage
      .from('project-files')
      .download(filePath);

    if (downloadError) {
      console.error('‚ùå Download error:', downloadError);
      return NextResponse.json(
        { error: 'Failed to download file' },
        { status: 500 }
      );
    }

    console.log(`‚úÖ Fichier t√©l√©charg√©: ${fileData.size} bytes`);

    // 2. Convertir le fichier en texte (selon le type)
    console.log('üìù Extraction du texte...');
    const fileText = await extractTextFromFile(fileData, fileName);

    if (!fileText) {
      console.error('‚ùå √âchec extraction texte');
      return NextResponse.json(
        { error: 'Failed to extract text from file' },
        { status: 500 }
      );
    }

    console.log(`‚úÖ Texte extrait: ${fileText.length} caract√®res`);
    console.log('üìÑ Aper√ßu du texte:');
    console.log(fileText.substring(0, 500));
    console.log('...');

    // 3. Analyser avec l'IA (en passant le secteur)
    console.log('ü§ñ Analyse IA en cours...');
    const analysis = await analyzeWithAI(fileText, fileName, sectorSlug, sectorName);

    if (!analysis) {
      console.error('‚ùå √âchec analyse IA');
      return NextResponse.json(
        { error: 'Failed to analyze file with AI' },
        { status: 500 }
      );
    }

    console.log(`‚úÖ Analyse IA termin√©e: ${analysis.materials?.length || 0} mat√©riaux d√©tect√©s`);
    console.log('üìä Cat√©gories d√©tect√©es:', [...new Set(analysis.materials?.map((m: any) => m.category) || [])]);

    // 4. Sauvegarder le mapping dans la base de donn√©es
    console.log('üíæ Sauvegarde du mapping...');
    const { error: mappingError } = await supabase
      .from('column_mappings')
      .insert({
        project_id: projectId,
        ai_mapping: analysis.mapping,
        user_mapping: null,
      });

    if (mappingError) {
      console.error('‚ùå Mapping save error:', mappingError);
      return NextResponse.json(
        { error: 'Failed to save mapping' },
        { status: 500 }
      );
    }

    // 5. Cr√©er les mat√©riaux d√©tect√©s
    if (analysis.materials && analysis.materials.length > 0) {
      const materialsToInsert = analysis.materials.map((material: any) => {
        // Enrichir les specs avec l'unit√© et la description si pr√©sentes
        const specs = material.specs || {};

        if (material.description) {
          specs.description = material.description;
        }

        if (material.unit) {
          specs.unit = material.unit;
        }

        return {
          project_id: projectId,
          name: material.name,
          category: material.category || null,
          quantity: material.quantity || null,
          specs: Object.keys(specs).length > 0 ? specs : null,
        };
      });

      console.log(`üíæ Insertion de ${materialsToInsert.length} mat√©riaux...`);

      const { error: materialsError } = await supabase
        .from('materials')
        .insert(materialsToInsert);

      if (materialsError) {
        console.error('‚ùå Materials insert error:', materialsError);
        console.log('‚ö†Ô∏è Continuing despite materials insert error...');
      } else {
        console.log(`‚úÖ ${materialsToInsert.length} mat√©riaux ins√©r√©s avec succ√®s`);
      }
    } else {
      console.warn('‚ö†Ô∏è Aucun mat√©riau d√©tect√© par l\'IA');
    }

    // 6. Mettre √† jour le statut du projet
    const { error: updateError } = await supabase
      .from('projects')
      .update({ mapping_status: 'completed' })
      .eq('id', projectId);

    if (updateError) {
      console.error('‚ùå Project update error:', updateError);
    }

    const duration = Date.now() - startTime;
    console.log(`‚úÖ === ANALYSE TERMIN√âE en ${duration}ms ===`);
    console.log(`üìä R√©sum√©: ${analysis.materials?.length || 0} mat√©riaux, mod√®le: ${analysis.model || 'gpt-4o-mini'}`);

    return NextResponse.json({
      success: true,
      mapping: analysis.mapping,
      materialsCount: analysis.materials?.length || 0,
      categories: [...new Set(analysis.materials?.map((m: any) => m.category) || [])],
      model: analysis.model,
      durationMs: duration,
      message: 'File analyzed successfully',
    });

  } catch (error) {
    console.error('‚ùå API Error:', error);
    return NextResponse.json(
      { error: 'Internal server error', details: error instanceof Error ? error.message : 'Unknown' },
      { status: 500 }
    );
  }
}

// Fonction pour extraire le texte selon le type de fichier
async function extractTextFromFile(file: Blob, fileName: string): Promise<string | null> {
  try {
    const fileExtension = fileName.split('.').pop()?.toLowerCase();

    // CSV et TXT - Lecture directe
    if (fileExtension === 'csv' || fileExtension === 'txt') {
      return await file.text();
    }

    // Excel - Parsing avec xlsx
    if (fileExtension === 'xlsx' || fileExtension === 'xls') {
      return await extractTextFromExcel(file);
    }

    // PDF - Parsing avec pdf-parse (import dynamique)
    if (fileExtension === 'pdf') {
      return await extractTextFromPDF(file, fileName);
    }

    return null;
  } catch (error) {
    console.error('Text extraction error:', error);
    return null;
  }
}

// Fonction pour extraire le texte d'un fichier Excel
async function extractTextFromExcel(file: Blob): Promise<string> {
  try {
    // Convertir le Blob en ArrayBuffer
    const arrayBuffer = await file.arrayBuffer();
    
    // Lire le fichier Excel avec toutes les options pour capturer le maximum de donn√©es
    const workbook = XLSX.read(arrayBuffer, { 
      type: 'array',
      cellDates: true,
      cellNF: false,
      cellText: false
    });
    
    // Prendre la premi√®re feuille
    const firstSheetName = workbook.SheetNames[0];
    const worksheet = workbook.Sheets[firstSheetName];
    
    // Convertir en CSV pour faciliter l'analyse
    const csvText = XLSX.utils.sheet_to_csv(worksheet, { 
      FS: ',',
      RS: '\n',
      blankrows: false // Ignorer les lignes vides
    });
    
    // Convertir aussi en JSON pour avoir la structure
    const jsonData = XLSX.utils.sheet_to_json(worksheet, { 
      header: 1,
      defval: '', // Valeur par d√©faut pour les cellules vides
      blankrows: false,
      raw: false // Convertir tout en texte
    });
    
    // Obtenir les headers (premi√®re ligne)
    const headers = jsonData[0] as any[];
    const dataRows = jsonData.slice(1);
    
    // Cr√©er une repr√©sentation enrichie
    let enrichedText = `Fichier Excel - Feuille: ${firstSheetName}
Nombre total de lignes: ${jsonData.length}
Nombre de lignes de donn√©es: ${dataRows.length}
Colonnes d√©tect√©es: ${headers.length}

=== EN-T√äTES ===
${headers.map((h, i) => `Colonne ${i + 1}: "${h}"`).join('\n')}

=== APER√áU DES DONN√âES (5 premi√®res lignes) ===
${dataRows.slice(0, 5).map((row: any, i: number) => {
  return `Ligne ${i + 1}: ${headers.map((h: any, j: number) => `${h}="${row[j] || ''}"`).join(' | ')}`;
}).join('\n')}

=== DONN√âES COMPL√àTES (CSV) ===
${csvText}

=== STATISTIQUES ===
- Lignes non vides: ${dataRows.filter((row: any) => row.some((cell: any) => cell && cell.toString().trim())).length}
- Colonnes avec donn√©es: ${headers.filter((h: any) => h && h.toString().trim()).length}
`;
    
    console.log('Excel extraction completed:', {
      sheet: firstSheetName,
      totalRows: jsonData.length,
      dataRows: dataRows.length,
      columns: headers.length
    });
    
    return enrichedText;
  } catch (error) {
    console.error('Excel extraction error:', error);
    throw new Error('Erreur lors de l\'extraction du fichier Excel');
  }
}

// Fonction pour extraire le texte d'un fichier PDF avec OCR
async function extractTextFromPDF(file: Blob, fileName: string): Promise<string> {
  // 1. Tentative pdf-parse (rapide & texte natif)
  try {
    console.log('üîÑ Tentative extraction PDF native (pdf-parse)...');
    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    const data = await pdfParse(buffer);
    const text = data.text;

    if (text && text.trim().length > 50) {
      console.log(`‚úÖ pdf-parse succ√®s: ${text.length} caract√®res`);
      return text;
    }
    console.log('‚ö†Ô∏è pdf-parse: texte insuffisant, bascule sur Vision...');
  } catch (e) {
    console.warn('‚ùå Erreur pdf-parse:', e);
  }

  try {
    console.log(`PDF OCR processing started for: ${fileName}`);
    
    // M√©thode 2: Utiliser GPT-4 Vision (RECOMMAND√â - Plus pr√©cis)
    return await extractTextFromPDFWithVision(file, fileName);
    
  } catch (visionError) {
    console.error('GPT-4 Vision failed, trying Tesseract OCR:', visionError);
    
    try {
      // M√©thode 3: Fallback vers Tesseract OCR
      return await extractTextFromPDFWithTesseract(file, fileName);
    } catch (tesseractError) {
      console.error('Tesseract OCR failed:', tesseractError);
      
      // M√©thode 3: Guide de conversion (dernier recours)
      return `üìÑ Fichier PDF d√©tect√©: ${fileName}

‚ö†Ô∏è L'extraction automatique a √©chou√©.

üîÑ Options disponibles:

1. **R√©essayer** - Le PDF peut √™tre trop complexe
2. **Convertir en Excel** - Meilleure qualit√© d'analyse
3. **Utiliser un OCR externe** - Google Drive, Adobe

üí° Pour de meilleurs r√©sultats:
‚Ä¢ Assurez-vous que le PDF contient du texte (pas juste des images)
‚Ä¢ Privil√©giez les fichiers Excel ou CSV
‚Ä¢ V√©rifiez que le fichier n'est pas corrompu

Erreurs rencontr√©es:
- Vision: ${visionError instanceof Error ? visionError.message : 'Erreur inconnue'}
- OCR: ${tesseractError instanceof Error ? tesseractError.message : 'Erreur inconnue'}`;
    }
  }
}

// M√©thode 1: GPT-4 Vision pour PDF (RECOMMAND√â)
async function extractTextFromPDFWithVision(file: Blob, fileName: string): Promise<string> {
  try {
    // Convertir le PDF en images avec pdf-lib
    const { PDFDocument } = await import('pdf-lib');
    const arrayBuffer = await file.arrayBuffer();
    const pdfDoc = await PDFDocument.load(arrayBuffer);
    
    const pageCount = pdfDoc.getPageCount();
    console.log(`PDF has ${pageCount} pages`);
    
    // Limiter √† 5 pages pour √©viter les co√ªts √©lev√©s
    const pagesToProcess = Math.min(pageCount, 5);
    
    // Pour chaque page, utiliser GPT-4 Vision
    let extractedText = `Fichier PDF: ${fileName}\nNombre de pages: ${pageCount}\n\n`;
    
    for (let i = 0; i < pagesToProcess; i++) {
      // Note: La conversion PDF ‚Üí Image n√©cessite canvas ou sharp
      // Pour simplifier, on utilise directement GPT-4 Vision avec le PDF
      extractedText += `--- Page ${i + 1} ---\n`;
      
      // GPT-4 Vision peut lire directement les PDF
      const pageText = await analyzePageWithVision(arrayBuffer, i);
      extractedText += pageText + '\n\n';
    }
    
    if (pageCount > pagesToProcess) {
      extractedText += `\n‚ö†Ô∏è Seules les ${pagesToProcess} premi√®res pages ont √©t√© analys√©es.\n`;
    }
    
    return extractedText;
    
  } catch (error) {
    console.error('PDF Vision extraction error:', error);
    throw error;
  }
}

// Analyser une page avec Gemini 2.0 Flash Vision
async function analyzePageWithVision(pdfBuffer: ArrayBuffer, pageIndex: number): Promise<string> {
  const gemini = getGeminiClient();
  if (!gemini) {
    return `[Gemini non configur√© - page ${pageIndex + 1}]`;
  }

  try {
    // Convertir le buffer en base64
    const base64 = Buffer.from(pdfBuffer).toString('base64');

    const model = gemini.getGenerativeModel({
      model: 'gemini-2.0-flash-exp',
      generationConfig: {
        temperature: 0.1,
        maxOutputTokens: 4000,
      },
    });

    // Utiliser Gemini Vision pour extraire le texte
    const result = await withTimeout(
      model.generateContent({
        contents: [{
          role: 'user',
          parts: [
            { text: `Extrait TOUT le texte de cette page de PDF. Liste CHAQUE √©l√©ment/mat√©riau sur une ligne s√©par√©e. Si c'est un tableau, structure-le en format CSV. Retourne uniquement le texte extrait, sans commentaire.` },
            {
              inlineData: {
                mimeType: 'application/pdf',
                data: base64,
              },
            },
          ],
        }],
      }),
      API_TIMEOUT_MS,
      `Gemini Vision timeout`
    );

    return result.response.text() || '';
  } catch (error: any) {
    console.error('Gemini Vision API error:', error?.message || error);
    return `[Erreur d'extraction pour la page ${pageIndex + 1}]`;
  }
}

// M√©thode 2: Tesseract OCR (Fallback)
async function extractTextFromPDFWithTesseract(file: Blob, fileName: string): Promise<string> {
  try {
    // Import dynamique de Tesseract
    const Tesseract = await import('tesseract.js');
    const { PDFDocument } = await import('pdf-lib');
    
    const arrayBuffer = await file.arrayBuffer();
    const pdfDoc = await PDFDocument.load(arrayBuffer);
    const pageCount = pdfDoc.getPageCount();
    
    let extractedText = `Fichier PDF (OCR): ${fileName}\nNombre de pages: ${pageCount}\n\n`;
    
    // Limiter √† 3 pages pour Tesseract (plus lent)
    const pagesToProcess = Math.min(pageCount, 3);
    
    for (let i = 0; i < pagesToProcess; i++) {
      extractedText += `--- Page ${i + 1} ---\n`;
      
      // Note: La conversion PDF ‚Üí Image n√©cessite une biblioth√®que suppl√©mentaire
      // Pour l'instant, on retourne un message
      extractedText += `[OCR Tesseract n√©cessite une conversion PDF ‚Üí Image]\n\n`;
    }
    
    return extractedText;
    
  } catch (error) {
    console.error('Tesseract OCR error:', error);
    throw error;
  }
}

// Fonction pour analyser avec l'IA (Gemini 2.0 Flash + DeepSeek fallback)
async function analyzeWithAI(fileContent: string, fileName: string, sectorSlug: string, sectorName: string) {
  // R√©cup√©rer les cat√©gories du secteur
  const categories = SECTOR_CATEGORIES[sectorSlug] || SECTOR_CATEGORIES['default'];

  const systemPrompt = `Tu es un expert en extraction de donn√©es pour le secteur ${sectorName}. Tu extrais TOUS les √©l√©ments/mat√©riaux pr√©sents dans les fichiers. Tu r√©ponds UNIQUEMENT en JSON valide.`;

  const prompt = `Tu es un EXPERT en extraction de donn√©es pour le secteur "${sectorName}".

**MISSION CRITIQUE**: Extrais TOUS les √©l√©ments/mat√©riaux/articles du fichier ci-dessous.

**CAT√âGORIES √Ä UTILISER (EXACTEMENT ces noms)**:
${categories.map(c => `‚Ä¢ ${c}`).join('\n')}

**R√àGLES D'EXTRACTION**:
1. Extrais CHAQUE ligne qui contient un √©l√©ment/mat√©riau/article
2. Un nom seul = √©l√©ment valide (quantit√© peut √™tre null)
3. Ignore: en-t√™tes, totaux, num√©ros de page, m√©tadonn√©es
4. S√©pare les √©l√©ments list√©s ensemble (ex: "gants, bottes, casques" = 3 items)
5. Corrige les fautes d'orthographe √©videntes
6. Cat√©gorise selon le secteur ${sectorName}

**Fichier**: ${fileName}

**Contenu** (${fileContent.length} caract√®res):
\`\`\`
${fileContent.substring(0, 15000)}
\`\`\`

**FORMAT JSON STRICT**:
{
  "mapping": {
    "columns": [{"original": "colonne", "mapped": "name|quantity|unit", "confidence": 0.9}],
    "detected_format": "pdf|csv|excel",
    "total_rows": 0
  },
  "materials": [
    {
      "name": "Nom court (OBLIGATOIRE)",
      "description": "D√©tails/specs ou null",
      "category": "Une des cat√©gories list√©es",
      "quantity": 10,
      "unit": "unit√© ou null"
    }
  ],
  "statistics": {
    "total_materials_found": 0,
    "by_category": {}
  }
}

R√âPONDS UNIQUEMENT EN JSON VALIDE, sans markdown.`;

  let responseText = '';
  let modelUsed = '';

  // 1. Essayer Gemini 2.0 Flash d'abord (rapide et efficace)
  const gemini = getGeminiClient();
  if (gemini) {
    try {
      console.log('ü§ñ Tentative avec Gemini 2.0 Flash...');
      const model = gemini.getGenerativeModel({
        model: 'gemini-2.0-flash-exp',
        generationConfig: {
          temperature: 0.1,
          maxOutputTokens: 8000,
          responseMimeType: 'application/json',
        },
      });

      const result = await withTimeout(
        model.generateContent({
          contents: [{
            role: 'user',
            parts: [{ text: `${systemPrompt}\n\n${prompt}` }]
          }],
        }),
        API_TIMEOUT_MS,
        `Gemini timeout after ${API_TIMEOUT_MS / 1000}s`
      );

      responseText = result.response.text()?.trim() || '';
      modelUsed = 'gemini-2.0-flash';
      console.log(`‚úÖ Gemini r√©ponse re√ßue: ${responseText.length} caract√®res`);
    } catch (error: any) {
      console.error('‚ùå Gemini error:', error?.message || error);
    }
  }

  // 2. Fallback DeepSeek si Gemini √©choue
  if (!responseText) {
    const deepseek = getDeepSeekClient();
    if (deepseek) {
      try {
        console.log('üîÑ Fallback vers DeepSeek...');
        const completion = await withTimeout(
          deepseek.chat.completions.create({
            model: 'deepseek-chat',
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: prompt },
            ],
            temperature: 0.1,
            max_tokens: 8000,
          }),
          API_TIMEOUT_MS,
          `DeepSeek timeout after ${API_TIMEOUT_MS / 1000}s`
        );

        responseText = completion.choices[0]?.message?.content?.trim() || '';
        modelUsed = 'deepseek-chat';
        console.log(`‚úÖ DeepSeek r√©ponse re√ßue: ${responseText.length} caract√®res`);
      } catch (error: any) {
        console.error('‚ùå DeepSeek error:', error?.message || error);
      }
    }
  }

  if (!responseText) {
    console.error('‚ùå Aucun mod√®le IA disponible');
    return null;
  }

  // Nettoyage et parsing JSON
  try {
    // Retirer les √©ventuels blocs markdown
    let cleanJson = responseText
      .replace(/```json\s*/gi, '')
      .replace(/```\s*/g, '');

    // Trouver le JSON
    const jsonMatch = cleanJson.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.error('‚ùå Pas de JSON trouv√© dans la r√©ponse');
      console.log('R√©ponse brute:', responseText.substring(0, 500));
      return null;
    }

    const parsedResponse = JSON.parse(jsonMatch[0]);

    // Ajouter le mod√®le utilis√©
    parsedResponse.model = modelUsed;

    console.log('üìä R√©sultats analyse:', {
      materialsFound: parsedResponse.materials?.length || 0,
      model: modelUsed,
      categories: [...new Set(parsedResponse.materials?.map((m: any) => m.category) || [])],
    });

    return parsedResponse;
  } catch (parseError) {
    console.error('‚ùå JSON parse error:', parseError);
    console.log('R√©ponse brute:', responseText.substring(0, 1000));
    return null;
  }
}
